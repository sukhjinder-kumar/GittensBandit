Date: 2024-12-11

- Don't use same line by Duff for solution to Bellman

- S0 for state vector, and s0 for arm, state

- Use i instead of a for arm

- Single run vs expectation run

- regret: optimal - cur (min regret)

- Don't average regret(?)

- Different initial temperature for linear schedule (min regret)

- QLearing should also have schedule

- Restless bandit (QWI algorithm)

- h(a, s) = h(s) ; homogoneous = a0 + a1*s + a2*s^2, polynomial representation

- Other mapping from h to pi.

- Think what does the maxima for h look like

- Change initial values of h [Burto and Sarto].
